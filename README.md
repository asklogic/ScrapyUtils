# 


### TODO:
1. pipeline to producer?.
2. producer in pool.
3. command 命令单元测试
4. RequestScraper header in flask.
5. command.thread.ScrapyConsumer 单个任务超时 -> 返回以及改为multiprocessing
6. datamodel 单元测试
7. PyUserInput



#### 重构scrapy逻辑

3. consuming:  
3.1 若引发普通异常(访问异常): 代理超时 页面assert失败等 清除缓存并且Task.count=+1
3.2 若引发单次任务超时异常(用户操作卡死): Scraper退出 消除上一个线程影响 _从Pool获取新的Scraper_ 直接关闭线程


## pipeline 保存文件

### collect step


##### thread.ScrapyConsumer 退出延时问题
##### collect preload测试 (新建mock scheme) √
##### Pipeline失败的model保存 (config文件路径 文件名字)
##### component的启停测试 √
##### Processor失败的日志打印 √

### block mark in firefox WebDriverWait √
### global and scheme settings √

## thread multiprocessing

Hello ption you need a fast worker for your data scraping. For your kind information I want to let you know that I have been working with these types of works for more than two years.

I am fully expert in web research, extracting email, data mining, and different website scraping. I used to crawl hundreds of thousands of government website data and save data in Mysql and Redis. I also have experience in web development that makes me quickly analyze the website.

I can assure you that I will be able to submit your task in time with quality work as I‘ve already completed so many projects. Please have a look on my portfolio and profile. I have crawled 60 detail page and saved in execl. 

I am waiting to be hired in this project to show my skills.
Regards
Logic